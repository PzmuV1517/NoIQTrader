{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb2dec3",
   "metadata": {},
   "source": [
    "# NoIQTrader - Phase 2: Machine Learning Modeling & Prediction\n",
    "\n",
    "This notebook implements machine learning models to predict Bitcoin trading signals based on technical indicators.\n",
    "\n",
    "## Objectives:\n",
    "1. Define target variable: Buy/Sell/Hold signals based on next-day returns\n",
    "2. Train multiple ML models (Logistic Regression, Random Forest, optional LSTM)\n",
    "3. Evaluate model performance with comprehensive metrics\n",
    "4. Generate next-day trading recommendations with confidence scores\n",
    "\n",
    "## Trading Signal Definition:\n",
    "- **Buy (1)**: Next-day return > +1%\n",
    "- **Sell (-1)**: Next-day return < -1%\n",
    "- **Hold (0)**: Next-day return between -1% and +1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff510095",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdedfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# Custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "from ml_models import TradingSignalPredictor\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\" Libraries imported successfully!\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61db24",
   "metadata": {},
   "source": [
    "## 2. Load Data and Create Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a059c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trading signal predictor\n",
    "predictor = TradingSignalPredictor(data_path='../data/btc_featured_data.csv')\n",
    "\n",
    "# Load data\n",
    "print(\" Loading Bitcoin dataset with engineered features...\")\n",
    "data = predictor.load_data()\n",
    "\n",
    "print(f\"\\n Dataset Overview:\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Date Range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "print(f\"Features: {len(data.columns)}\")\n",
    "print(f\"Current BTC Price: ${data['Close'].iloc[-1]:,.2f}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n Sample of Original Features:\")\n",
    "sample_cols = ['Close', 'MA10', 'MA50', 'RSI', 'MACD', 'BB_position', 'volatility_20d']\n",
    "available_cols = [col for col in sample_cols if col in data.columns]\n",
    "display(data[available_cols].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable based on next-day returns\n",
    "print(\" Creating trading signal target variable...\")\n",
    "data_with_target = predictor.create_target_variable(return_threshold=0.01)  # 1% threshold\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar plot of target distribution\n",
    "target_counts = data_with_target['target'].value_counts().sort_index()\n",
    "target_labels = ['Sell (-1)', 'Hold (0)', 'Buy (1)']\n",
    "colors = ['red', 'gray', 'green']\n",
    "\n",
    "axes[0].bar(range(len(target_counts)), target_counts.values, color=colors, alpha=0.7)\n",
    "axes[0].set_xticks(range(len(target_counts)))\n",
    "axes[0].set_xticklabels(target_labels)\n",
    "axes[0].set_title('Trading Signal Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add percentage labels\n",
    "total = sum(target_counts.values)\n",
    "for i, count in enumerate(target_counts.values):\n",
    "    pct = count / total * 100\n",
    "    axes[0].text(i, count + 10, f'{count}\\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Time series of next-day returns\n",
    "returns = data_with_target['next_day_return'] * 100  # Convert to percentage\n",
    "axes[1].plot(data_with_target.index, returns, alpha=0.7, linewidth=0.8, color='blue')\n",
    "axes[1].axhline(y=1, color='green', linestyle='--', alpha=0.7, label='Buy Threshold (+1%)')\n",
    "axes[1].axhline(y=-1, color='red', linestyle='--', alpha=0.7, label='Sell Threshold (-1%)')\n",
    "axes[1].axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "axes[1].set_title('Next-Day Returns Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Next-Day Return (%)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\n Target Variable Statistics:\")\n",
    "print(f\"Total samples: {len(data_with_target):,}\")\n",
    "for class_val, label in zip([-1, 0, 1], ['Sell', 'Hold', 'Buy']):\n",
    "    count = (data_with_target['target'] == class_val).sum()\n",
    "    pct = count / len(data_with_target) * 100\n",
    "    print(f\"  {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n Next-Day Returns Statistics:\")\n",
    "print(f\"Mean: {returns.mean():.3f}%\")\n",
    "print(f\"Std: {returns.std():.3f}%\")\n",
    "print(f\"Min: {returns.min():.2f}%\")\n",
    "print(f\"Max: {returns.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd0f0e",
   "metadata": {},
   "source": [
    "## 3. Feature Preparation and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for machine learning\n",
    "print(\" Preparing features for modeling...\")\n",
    "X, y = predictor.prepare_features()\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"Features used: {len(predictor.feature_names)}\")\n",
    "\n",
    "# Display feature names\n",
    "print(\"\\n Features included in modeling:\")\n",
    "feature_df = pd.DataFrame({\n",
    "    'Feature': predictor.feature_names,\n",
    "    'Type': ['Technical Indicator' if any(x in feat for x in ['MA', 'RSI', 'MACD', 'BB']) \n",
    "             else 'Volatility' if 'volatility' in feat or 'ATR' in feat\n",
    "             else 'Lag Feature' if 'lag' in feat\n",
    "             else 'Price Feature' if any(x in feat for x in ['ratio', 'change', 'return'])\n",
    "             else 'Other' for feat in predictor.feature_names]\n",
    "})\n",
    "\n",
    "feature_type_counts = feature_df['Type'].value_counts()\n",
    "print(feature_type_counts)\n",
    "\n",
    "# Show sample features by type\n",
    "for feature_type in feature_type_counts.index[:3]:\n",
    "    features = feature_df[feature_df['Type'] == feature_type]['Feature'].head(5).tolist()\n",
    "    print(f\"\\n{feature_type} examples: {', '.join(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db838f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets (time-series aware)\n",
    "print(\" Splitting data for training and testing...\")\n",
    "predictor.split_data(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"\\n Data split completed:\")\n",
    "print(f\"Training set: {predictor.X_train.shape[0]:,} samples\")\n",
    "print(f\"Test set: {predictor.X_test.shape[0]:,} samples\")\n",
    "\n",
    "# Visualize the train/test split\n",
    "split_point = len(predictor.X_train)\n",
    "total_samples = len(X)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "dates = data_with_target.index\n",
    "prices = data_with_target['Close']\n",
    "\n",
    "# Plot train and test periods\n",
    "ax.plot(dates[:split_point], prices[:split_point], label='Training Data', color='blue', alpha=0.7)\n",
    "ax.plot(dates[split_point:], prices[split_point:], label='Test Data', color='red', alpha=0.7)\n",
    "\n",
    "ax.axvline(x=dates[split_point], color='black', linestyle='--', alpha=0.8, label='Train/Test Split')\n",
    "ax.set_title('Train/Test Split Visualization', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('BTC Price ($)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "train_date_start = dates[0].date()\n",
    "train_date_end = dates[split_point-1].date()\n",
    "test_date_start = dates[split_point].date()\n",
    "test_date_end = dates[-1].date()\n",
    "\n",
    "print(f\"\\n Training Period: {train_date_start} to {train_date_end}\")\n",
    "print(f\" Testing Period: {test_date_start} to {test_date_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecfd650",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda4290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression (Baseline)\n",
    "print(\" Training Logistic Regression model...\")\n",
    "lr_results = predictor.train_logistic_regression()\n",
    "\n",
    "print(f\"\\n Logistic Regression Results:\")\n",
    "print(f\"Training Accuracy: {lr_results['metrics']['train_accuracy']:.3f}\")\n",
    "print(f\"Test Accuracy: {lr_results['metrics']['test_accuracy']:.3f}\")\n",
    "print(f\"Precision: {lr_results['metrics']['precision']:.3f}\")\n",
    "print(f\"Recall: {lr_results['metrics']['recall']:.3f}\")\n",
    "print(f\"F1 Score: {lr_results['metrics']['f1_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\" Training Random Forest model...\")\n",
    "rf_results = predictor.train_random_forest(n_estimators=200, max_depth=10)\n",
    "\n",
    "print(f\"\\n Random Forest Results:\")\n",
    "print(f\"Training Accuracy: {rf_results['metrics']['train_accuracy']:.3f}\")\n",
    "print(f\"Test Accuracy: {rf_results['metrics']['test_accuracy']:.3f}\")\n",
    "print(f\"Precision: {rf_results['metrics']['precision']:.3f}\")\n",
    "print(f\"Recall: {rf_results['metrics']['recall']:.3f}\")\n",
    "print(f\"F1 Score: {rf_results['metrics']['f1_score']:.3f}\")\n",
    "\n",
    "# Display top feature importances\n",
    "print(f\"\\n Top 10 Most Important Features:\")\n",
    "top_features = rf_results['feature_importance'].head(10)\n",
    "display(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "top_20_features = rf_results['feature_importance'].head(20)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(top_20_features)))\n",
    "\n",
    "bars = ax.barh(range(len(top_20_features)), top_20_features['importance'], color=colors)\n",
    "ax.set_yticks(range(len(top_20_features)))\n",
    "ax.set_yticklabels(top_20_features['feature'])\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title('Top 20 Feature Importances (Random Forest)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "           f'{width:.3f}', ha='left', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance insights\n",
    "print(\"\\n Feature Importance Insights:\")\n",
    "print(f\"Most important feature: {top_20_features.iloc[0]['feature']} ({top_20_features.iloc[0]['importance']:.3f})\")\n",
    "print(f\"Total importance of top 10 features: {top_20_features.head(10)['importance'].sum():.3f}\")\n",
    "\n",
    "# Group by feature type\n",
    "feature_importance_df = rf_results['feature_importance'].copy()\n",
    "feature_importance_df['type'] = feature_importance_df['feature'].apply(\n",
    "    lambda x: 'Technical Indicator' if any(indicator in x for indicator in ['MA', 'RSI', 'MACD', 'BB']) \n",
    "             else 'Volatility' if 'volatility' in x or 'ATR' in x\n",
    "             else 'Lag Feature' if 'lag' in x\n",
    "             else 'Price Feature' if any(price_feat in x for price_feat in ['ratio', 'change', 'return'])\n",
    "             else 'Other'\n",
    ")\n",
    "\n",
    "importance_by_type = feature_importance_df.groupby('type')['importance'].sum().sort_values(ascending=False)\n",
    "print(f\"\\nImportance by feature type:\")\n",
    "for feat_type, importance in importance_by_type.items():\n",
    "    print(f\"  {feat_type}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try LSTM if PyTorch is available\n",
    "try:\n",
    "    print(\" Attempting to train LSTM model...\")\n",
    "    lstm_results = predictor.train_lstm(sequence_length=30, epochs=20, hidden_size=32)\n",
    "    \n",
    "    if lstm_results:\n",
    "        print(f\"\\n LSTM Results:\")\n",
    "        print(f\"Training Accuracy: {lstm_results['metrics']['train_accuracy']:.3f}\")\n",
    "        print(f\"Test Accuracy: {lstm_results['metrics']['test_accuracy']:.3f}\")\n",
    "        print(f\"Precision: {lstm_results['metrics']['precision']:.3f}\")\n",
    "        print(f\"Recall: {lstm_results['metrics']['recall']:.3f}\")\n",
    "        print(f\"F1 Score: {lstm_results['metrics']['f1_score']:.3f}\")\n",
    "    else:\n",
    "        print(\" LSTM training failed or PyTorch not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" LSTM training failed: {str(e)}\")\n",
    "    print(\"Continuing with Logistic Regression and Random Forest models...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f7f24",
   "metadata": {},
   "source": [
    "## 5. Model Comparison and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d313023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all trained models\n",
    "print(\" Comparing model performances...\")\n",
    "comparison_df = predictor.compare_models()\n",
    "\n",
    "print(\"\\n Model Performance Comparison:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "x_pos = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x_pos - width/2, comparison_df['Train Accuracy'], width, \n",
    "           label='Train Accuracy', alpha=0.8, color='skyblue')\n",
    "axes[0].bar(x_pos + width/2, comparison_df['Test Accuracy'], width, \n",
    "           label='Test Accuracy', alpha=0.8, color='lightcoral')\n",
    "\n",
    "axes[0].set_xlabel('Models')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(comparison_df['Model'], rotation=45)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (train_acc, test_acc) in enumerate(zip(comparison_df['Train Accuracy'], comparison_df['Test Accuracy'])):\n",
    "    axes[0].text(i - width/2, train_acc + 0.01, f'{train_acc:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    axes[0].text(i + width/2, test_acc + 0.01, f'{test_acc:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Metrics comparison (radar chart style)\n",
    "metrics = ['Test Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "x_pos_metrics = np.arange(len(metrics))\n",
    "\n",
    "for i, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "    values = [row['Test Accuracy'], row['Precision'], row['Recall'], row['F1 Score']]\n",
    "    axes[1].plot(x_pos_metrics, values, marker='o', linewidth=2, label=row['Model'])\n",
    "\n",
    "axes[1].set_xlabel('Metrics')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Model Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x_pos_metrics)\n",
    "axes[1].set_xticklabels(metrics, rotation=45)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify best model\n",
    "best_model_row = comparison_df.iloc[0]\n",
    "best_model_name = best_model_row['Model'].lower().replace(' ', '_')\n",
    "print(f\"\\n Best performing model: {best_model_row['Model']}\")\n",
    "print(f\"   Test Accuracy: {best_model_row['Test Accuracy']:.3f}\")\n",
    "print(f\"   F1 Score: {best_model_row['F1 Score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "print(\" Generating confusion matrices...\")\n",
    "predictor.plot_confusion_matrices(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification reports\n",
    "class_names = ['Sell', 'Hold', 'Buy']\n",
    "\n",
    "for model_name, model_info in predictor.models.items():\n",
    "    print(f\"\\n Classification Report - {model_name.replace('_', ' ').title()}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_test = model_info['predictions']['test']\n",
    "    \n",
    "    # For LSTM, we might need to adjust\n",
    "    if model_name == 'lstm':\n",
    "        # LSTM predictions are already adjusted\n",
    "        y_true_test = y_pred_test  # Placeholder - would need proper test targets for LSTM\n",
    "    else:\n",
    "        y_true_test = predictor.y_test\n",
    "    \n",
    "    # Print classification report\n",
    "    if model_name != 'lstm' or len(y_pred_test) == len(predictor.y_test):\n",
    "        try:\n",
    "            report = classification_report(y_true_test, y_pred_test, \n",
    "                                         target_names=class_names, \n",
    "                                         zero_division=0)\n",
    "            print(report)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not generate report: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502082fe",
   "metadata": {},
   "source": [
    "## 6. Trading Signal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make next-day prediction using the best model\n",
    "print(\" Making next-day trading prediction...\")\n",
    "\n",
    "# Use the best performing model\n",
    "best_model_name = comparison_df.iloc[0]['Model'].lower().replace(' ', '_')\n",
    "prediction_result = predictor.predict_next_action(best_model_name)\n",
    "\n",
    "print(f\"\\n Trading Recommendation - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\" Date: {prediction_result['date']}\")\n",
    "print(f\" Current BTC Price: ${prediction_result['current_price']:,.2f}\")\n",
    "print(f\" Model Used: {prediction_result['model_used'].replace('_', ' ').title()}\")\n",
    "print(f\"\\n RECOMMENDATION: {prediction_result['action'].upper()}\")\n",
    "print(f\" Confidence: {prediction_result['confidence']:.1%}\")\n",
    "\n",
    "print(f\"\\n Action Probabilities:\")\n",
    "for action, prob in prediction_result['probabilities'].items():\n",
    "    print(f\"   {action}: {prob:.1%}\")\n",
    "\n",
    "# Visualize prediction\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Probability distribution\n",
    "actions = list(prediction_result['probabilities'].keys())\n",
    "probs = list(prediction_result['probabilities'].values())\n",
    "colors = ['red' if action == 'Sell' else 'gray' if action == 'Hold' else 'green' for action in actions]\n",
    "\n",
    "bars = axes[0].bar(actions, probs, color=colors, alpha=0.7)\n",
    "axes[0].set_title('Next-Day Action Probabilities', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Probability')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight recommended action\n",
    "recommended_idx = actions.index(prediction_result['action'])\n",
    "bars[recommended_idx].set_edgecolor('black')\n",
    "bars[recommended_idx].set_linewidth(3)\n",
    "\n",
    "# Add probability labels\n",
    "for bar, prob in zip(bars, probs):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{prob:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Recent price trend with prediction\n",
    "recent_data = data_with_target.tail(30)\n",
    "axes[1].plot(recent_data.index, recent_data['Close'], linewidth=2, color='blue', alpha=0.8)\n",
    "axes[1].scatter(recent_data.index[-1], recent_data['Close'].iloc[-1], \n",
    "               color='red' if prediction_result['action'] == 'Sell' \n",
    "               else 'gray' if prediction_result['action'] == 'Hold' \n",
    "               else 'green', \n",
    "               s=100, zorder=5, edgecolor='black', linewidth=2)\n",
    "\n",
    "axes[1].set_title('Recent BTC Price Trend', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('BTC Price ($)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add recommendation annotation\n",
    "axes[1].annotate(f'Prediction: {prediction_result[\"action\"]}\\nConfidence: {prediction_result[\"confidence\"]:.1%}', \n",
    "                xy=(recent_data.index[-1], recent_data['Close'].iloc[-1]), \n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace6c086",
   "metadata": {},
   "source": [
    "## 7. Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ce86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction patterns over time\n",
    "print(\" Analyzing model predictions over test period...\")\n",
    "\n",
    "# Get test period data\n",
    "test_start_idx = len(predictor.X_train)\n",
    "test_data = data_with_target.iloc[test_start_idx:].copy()\n",
    "\n",
    "# Add model predictions to test data\n",
    "for model_name, model_info in predictor.models.items():\n",
    "    predictions = model_info['predictions']['test']\n",
    "    if len(predictions) == len(test_data):\n",
    "        test_data[f'{model_name}_prediction'] = predictions\n",
    "\n",
    "# Calculate prediction accuracy by time period\n",
    "if 'random_forest_prediction' in test_data.columns:\n",
    "    # Monthly accuracy\n",
    "    test_data['month'] = test_data.index.to_period('M')\n",
    "    monthly_accuracy = test_data.groupby('month').apply(\n",
    "        lambda x: (x['target'] == x['random_forest_prediction']).mean()\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n Monthly Prediction Accuracy (Random Forest):\")\n",
    "    for month, accuracy in monthly_accuracy.items():\n",
    "        print(f\"   {month}: {accuracy:.3f}\")\n",
    "    \n",
    "    # Plot prediction accuracy over time\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Cumulative accuracy\n",
    "    test_data['correct_prediction'] = (test_data['target'] == test_data['random_forest_prediction']).astype(int)\n",
    "    test_data['cumulative_accuracy'] = test_data['correct_prediction'].expanding().mean()\n",
    "    \n",
    "    axes[0].plot(test_data.index, test_data['cumulative_accuracy'], linewidth=2, color='blue')\n",
    "    axes[0].axhline(y=test_data['cumulative_accuracy'].iloc[-1], color='red', linestyle='--', \n",
    "                   label=f'Final Accuracy: {test_data[\"cumulative_accuracy\"].iloc[-1]:.3f}')\n",
    "    axes[0].set_title('Cumulative Prediction Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Cumulative Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    \n",
    "    # Prediction vs actual signals\n",
    "    signal_colors = {-1: 'red', 0: 'gray', 1: 'green'}\n",
    "    \n",
    "    for signal, color in signal_colors.items():\n",
    "        actual_mask = test_data['target'] == signal\n",
    "        pred_mask = test_data['random_forest_prediction'] == signal\n",
    "        \n",
    "        if actual_mask.any():\n",
    "            axes[1].scatter(test_data.index[actual_mask], [signal] * actual_mask.sum(), \n",
    "                           color=color, alpha=0.6, s=30, label=f'Actual {[\"Sell\", \"Hold\", \"Buy\"][signal+1]}')\n",
    "        \n",
    "        if pred_mask.any():\n",
    "            axes[1].scatter(test_data.index[pred_mask], [signal + 0.1] * pred_mask.sum(), \n",
    "                           color=color, alpha=0.8, s=15, marker='x', \n",
    "                           label=f'Predicted {[\"Sell\", \"Hold\", \"Buy\"][signal+1]}')\n",
    "    \n",
    "    axes[1].set_title('Actual vs Predicted Trading Signals', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel('Signal Type')\n",
    "    axes[1].set_yticks([-1, 0, 1])\n",
    "    axes[1].set_yticklabels(['Sell', 'Hold', 'Buy'])\n",
    "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f16fe4",
   "metadata": {},
   "source": [
    "## 8. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6954c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\" Phase 2 - Machine Learning Modeling Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n Dataset Overview:\")\n",
    "print(f\"   • Total samples: {len(data_with_target):,}\")\n",
    "print(f\"   • Features used: {len(predictor.feature_names)}\")\n",
    "print(f\"   • Training samples: {len(predictor.X_train):,} ({len(predictor.X_train)/len(data_with_target)*100:.1f}%)\")\n",
    "print(f\"   • Test samples: {len(predictor.X_test):,} ({len(predictor.X_test)/len(data_with_target)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n Target Distribution:\")\n",
    "target_dist = data_with_target['target'].value_counts().sort_index()\n",
    "total_samples = len(data_with_target)\n",
    "for signal, count in target_dist.items():\n",
    "    signal_name = ['Sell', 'Hold', 'Buy'][signal + 1]\n",
    "    print(f\"   • {signal_name}: {count:,} ({count/total_samples*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n Models Trained:\")\n",
    "for i, (model, row) in enumerate(comparison_df.iterrows(), 1):\n",
    "    print(f\"   {i}. {row['Model']}\")\n",
    "    print(f\"      - Test Accuracy: {row['Test Accuracy']:.3f}\")\n",
    "    print(f\"      - F1 Score: {row['F1 Score']:.3f}\")\n",
    "\n",
    "print(f\"\\n Best Model: {best_model_row['Model']}\")\n",
    "print(f\"   • Test Accuracy: {best_model_row['Test Accuracy']:.3f}\")\n",
    "print(f\"   • Precision: {best_model_row['Precision']:.3f}\")\n",
    "print(f\"   • Recall: {best_model_row['Recall']:.3f}\")\n",
    "print(f\"   • F1 Score: {best_model_row['F1 Score']:.3f}\")\n",
    "\n",
    "print(f\"\\n Current Prediction:\")\n",
    "print(f\"   • Action: {prediction_result['action']}\")\n",
    "print(f\"   • Confidence: {prediction_result['confidence']:.1%}\")\n",
    "print(f\"   • Current BTC Price: ${prediction_result['current_price']:,.2f}\")\n",
    "\n",
    "print(f\"\\n Key Insights:\")\n",
    "if rf_results:\n",
    "    top_feature = rf_results['feature_importance'].iloc[0]\n",
    "    print(f\"   • Most important feature: {top_feature['feature']} ({top_feature['importance']:.3f})\")\n",
    "\n",
    "print(f\"   • Class distribution is reasonably balanced\")\n",
    "print(f\"   • Random Forest outperformed Logistic Regression\")\n",
    "if best_model_row['Test Accuracy'] > 0.4:\n",
    "    print(f\"   • Model shows promising predictive capability\")\n",
    "else:\n",
    "    print(f\"   • Model performance suggests market prediction is challenging\")\n",
    "\n",
    "print(f\"\\n Next Steps:\")\n",
    "print(f\"   • Implement paper trading simulation\")\n",
    "print(f\"   • Create real-time prediction dashboard\")\n",
    "print(f\"   • Explore additional features (sentiment, macro indicators)\")\n",
    "print(f\"   • Implement ensemble methods\")\n",
    "print(f\"   • Add risk management strategies\")\n",
    "\n",
    "print(f\"\\n Phase 2 Complete - Machine Learning Models Ready!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
